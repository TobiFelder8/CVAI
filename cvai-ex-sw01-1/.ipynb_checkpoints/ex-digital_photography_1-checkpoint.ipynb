{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "102e2134",
   "metadata": {},
   "source": [
    "# CVAI Exercise Digital Photography\n",
    "\n",
    "Most algorithms to use for digital photography are quite complex and therefor often implemented in specialized software like Adobe Lightroom or Photoshop.\n",
    "\n",
    "In this exercise we will look as some simple examples that should also demonstrate more how to work with images in python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f99521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import numpy as np\n",
    "\n",
    "# for displaying images in jupyter\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# this makes the images a bit larger\n",
    "mpl.rcParams['figure.dpi']= 200\n",
    "plt.rcParams['figure.figsize'] = [5,4]\n",
    "\n",
    "# plots directly in the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# if you have a high-dpis monitor\n",
    "%config InlineBackend.figure_format = 'retina' \n",
    "\n",
    "path = '/exchange/cvai/images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3d13dd",
   "metadata": {},
   "source": [
    "### Skimage package\n",
    "\n",
    "We will use OpenCV and Skimage as image processing libraries in the exercises. Skimage integrates well with other python machine learning libraries, documentation is available at https://scikit-image.org\n",
    "\n",
    "So we will quickly examine how we can use that to load and process images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images can be read using imread, this will result in a 3 channel uint8 image\n",
    "image = skimage.io.imread(path + 'lena_std.tif')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [7,7]\n",
    "plt.imshow(image)\n",
    "print(image.dtype)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ef51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are different color transformation functions available, for example rgb2gray\n",
    "# (alternatively it is als possible to read gray images directly)\n",
    "image_gray = skimage.color.rgb2gray(image)\n",
    "plt.imshow(image_gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b009b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use a closeup of the image to better see the results\n",
    "detail = image[250:300,300:350,:]\n",
    "plt.imshow(detail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3061eb5e",
   "metadata": {},
   "source": [
    "### Mosaicing\n",
    "\n",
    "For the first exercise, we will look at demosaicing techniques. However instead of using a proper RAW image (those are quite large), we will instead simulate the mosaicing process on the given image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787938fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaic_bayer(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simulate mosaicing of the given (3 channel image) using the Bayer pattern. Green is always present in each row,\n",
    "    alternating with blue and red.\n",
    "    The resulting image will contain a value of 0 on the masked spots.\n",
    "    \"\"\"\n",
    "    # generate the target image of the same size as the original\n",
    "    m = np.zeros_like(image)\n",
    "    \n",
    "    # this is not very efficient, but shows how the image is constructed\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            if i % 2 == 0:\n",
    "                if j % 2 == 0:\n",
    "                    # G\n",
    "                    m[i,j,1] = image[i,j,1]\n",
    "                else:\n",
    "                    # B\n",
    "                    m[i,j,2] = image[i,j,2]\n",
    "            else:\n",
    "                if j % 2 == 0:\n",
    "                    # R\n",
    "                    m[i,j,0] = image[i,j,0]\n",
    "                else:\n",
    "                    # G\n",
    "                    m[i,j,1] = image[i,j,1]\n",
    "    return m\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c5499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic = mosaic_bayer(image)\n",
    "plt.imshow(mosaic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d95028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us look at a detail\n",
    "mosaic_detail = mosaic[250:300,300:350,:]\n",
    "plt.imshow(mosaic_detail)"
   ]
  },
  {
   "attachments": {
    "Bayer_matrix.svg.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAANwAAACKCAMAAAD2U9RZAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAWlBMVEUA/wAAv0AAAP8Af4AAP8AzzAAmrisAM8wZilwMYZL/AADAPwCAfwBAvwCZZgByfw4AmWZMjyQmmEHMMwCZYQUAzDNmig8zrh5mmQBMmBsAZpkzjz0Zf2f///8q4tc6AAAAAWJLR0Qd6wNxkQAAAAd0SU1FB+UEHAEQIBV8NtgAAAD8SURBVHja7do3DgMwDANAp/fey//fmVWaYiBZbBxXgsN5E+BSYgbDmFHqxqlrbwYHBwcHBwcHBwf3y2wSM53FzFO3SF0Ts7KMWaVnWKduk7omZnBwcHBwcHBwcHB/w21jdvuYQ+qOqWti5liFg4ODg4ODg4ODq5l1fRU4VuHg4ODg4ODg4OAqcF3/IHKswsHBwcHBwcHBwVXM3HNwcHBwcHBwcHBwFbhTzPkSc03dLXVNzNxzcHBwcHBwcHBwcDWze8zjGfNK3Tt1Tcwcq3BwcHBwcHBwcHA1uK6vAscqHBwcHBwcHBwcXMWs6x9EjlU4ODg4ODg4ODi477MPoJzbsP5u9lsAAAAldEVYdGRhdGU6Y3JlYXRlADIwMjEtMDQtMjhUMDE6MTY6MzIrMDA6MDBd5WCQAAAAJXRFWHRkYXRlOm1vZGlmeQAyMDIxLTA0LTI4VDAxOjE2OjMyKzAwOjAwLLjYLAAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "118aba69",
   "metadata": {},
   "source": [
    "## Exercise 1: Demosaicing\n",
    "\n",
    "We would now like to reconstruct the image from the mosaic image, i.e. that is the same task that the camera must do with the output of the raw sensor data. We will implement 3 different methods and compare the results.\n",
    "\n",
    "### Nearest Neighbor\n",
    "In the first method, we will take the nearest neighbor of any color value that we do not have at a specific location. So for example, at the locations for the red pixel, we can take the green value from the neighbor to the left, and the blue value from a diagonal neighbor of the upper left. For simplification of the code, we will leave a 1-pixel border in the resulting image.\n",
    "\n",
    "In order to get the same result as in the solution, use neighbors with lower coordinate values, i.e. for pixel (i,j) use the neighbors (i-1,j), (i,j-1) and (i-1,j-1).\n",
    "\n",
    "Here the arrangment of the pixel values\n",
    "\n",
    "![Bayer_matrix.svg.png](attachment:Bayer_matrix.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1ddef",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1445860270e217579982f407e62695f3",
     "grade": false,
     "grade_id": "cell-bca321e0f85dbc4f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def demosaic_nn(image:np.ndarray)->np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement demosaicing of the input image using nearest neighbor.\n",
    "    \"\"\"\n",
    "    # generate the target image of the same size as the original\n",
    "    d = np.zeros_like(image)\n",
    "  \n",
    "    for i in range(1, image.shape[0] - 1):\n",
    "        for j in range(1, image.shape[1] - 1):                       \n",
    "            if i % 2 == 1: \n",
    "                if j % 2 == 0:\n",
    "                    # Case Red (0)\n",
    "                    d[i, j, 0] = image[i, j, 0]  # Rot behalten\n",
    "                    d[i, j, 1] = image[i, j-1, 1]  # Grün von links\n",
    "                    d[i, j, 2] = image[i-1, j-1, 2]  # Blau von oben\n",
    "                else:\n",
    "                    # Case Green (1)\n",
    "                    d[i, j, 0] = image[i, j-1, 0]  # Rot von links\n",
    "                    d[i, j, 1] = image[i, j, 1]  # Grün behalten\n",
    "                    d[i, j, 2] = image[i-1, j, 2]  # Blau von oben\n",
    "            else: \n",
    "                if j % 2 == 1:\n",
    "                    # Case Blue (2)\n",
    "                    d[i, j, 0] = image[i-1, j-1, 0]  # Rot diagonal oben links\n",
    "                    d[i, j, 1] = image[i, j-1, 1]  # Grün von links\n",
    "                    d[i, j, 2] = image[i, j, 2]  # Blau behalten\n",
    "                else:\n",
    "                    # Case Green (1) (zwischen B und R)\n",
    "                    d[i, j, 0] = image[i-1, j, 0]  # Rot von oben\n",
    "                    d[i, j, 1] = image[i, j, 1]  # Grün behalten\n",
    "                    d[i, j, 2] = image[i, j-1, 2]  # Blau von links\n",
    "\n",
    "    return d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b396527",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a81ee18388ee59558d10d98c351ebf8",
     "grade": true,
     "grade_id": "cell-c94b5ff058051d76",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "d_nn = demosaic_nn(mosaic)\n",
    "d_nn_detail = d_nn[250:300,300:350,:]\n",
    "\n",
    "# we will check some arbitrary value for each of the 4 cases\n",
    "np.testing.assert_array_equal(d_nn[260, 360,:], [86, 18, 54])\n",
    "np.testing.assert_array_equal(d_nn[261, 360,:], [87, 17, 54])\n",
    "np.testing.assert_array_equal(d_nn[260, 361,:], [86, 18, 61])\n",
    "np.testing.assert_array_equal(d_nn[261, 361,:], [87, 26, 61])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c3ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(d_nn_detail) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16c609",
   "metadata": {},
   "source": [
    "### Averaging neighbors\n",
    "\n",
    "The results are not bad, but we can see that the red and blue values have lost some of the resolution, as they\n",
    "are the same in 2x2 blocks. A slightly better version, is to average each of the pixel values from the 2 or 4 nearest values. As you can see from the Bayer matrix, at the position where a green pixel is defined, the red and blue colors can be interpolated from 2 neighboring values. At the position where the green pixels are defined, 4 neighboring values can be used for red and blue.\n",
    "\n",
    "One problem that you might have to deal with, is that the original image contains unsigned 8bit values and there might be an overflow when you add them. One possibility to deal with that, is to convert the image first to 32bit integers and do all calculation there. The resulting average should again fit into 8bit, so the result is again an 8bit image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16413cef",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4f4b8b1048a50d4cfddc0ab1b092ce9",
     "grade": false,
     "grade_id": "cell-23c5cf160230ab44",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def demosaic_average(image_8bit:np.ndarray)->np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement demosaicing of the input image using averaging of 4 neighbors.\n",
    "    \"\"\"\n",
    "    # generate the target image of the same size as the original\n",
    "    d = np.zeros_like(image_8bit)\n",
    "    \n",
    "    # convert image to int before processing\n",
    "    image = image_8bit.astype(int)\n",
    "    image_32bit = image_8bit.astype(np.int32)\n",
    "\n",
    "    for i in range(1, image.shape[0] - 1):\n",
    "        for j in range(1, image.shape[1] - 1):                       \n",
    "            if i % 2 == 1:  # Ungerade Zeilen (Rote und Grüne Pixel)\n",
    "                if j % 2 == 0:\n",
    "                    # Fall für Rot (0)\n",
    "                    d[i, j, 0] = image[i, j, 0]  # Rot behalten\n",
    "                    d[i, j, 1] = (image[i, j-1, 1] + image[i, j+1, 1] + image[i-1, j, 1] + image[i + 1,j, 1]) / 4  # Grün von links und rechts\n",
    "                    d[i, j, 2] = (image[i-1, j-1, 2] + image[i+1, j-1, 2] + image[i+1, j+1, 2] + image[i-1, j+1, 2]) / 4  # Blau von oben und unten\n",
    "                else:\n",
    "                    # Fall für Grün (1)\n",
    "                    d[i, j, 0] = (image[i, j-1, 0] + image[i, j+1, 0]) / 2  # Rot von links und rechts\n",
    "                    d[i, j, 1] = image[i, j, 1]  # Grün behalten\n",
    "                    d[i, j, 2] = (image[i-1, j, 2] + image[i+1, j, 2]) / 2  # Blau von oben und unten\n",
    "            else:  # Gerade Zeilen (Grüne und Blaue Pixel)\n",
    "                if j % 2 == 1:\n",
    "                    # Fall für Blau (2)\n",
    "                    d[i, j, 0] = (image[i-1, j-1, 0] + image[i+1, j-1, 0] + image[i+1, j+1, 0] + image[i-1, j+1, 0]) / 4  # Rot diagonal oben links und unten links\n",
    "                    d[i, j, 1] = (image[i, j-1, 1] + image[i, j+1, 1] + image[i-1, j, 1] + image[i+1,j,1]) / 4  # Grün von links und rechts\n",
    "                    d[i, j, 2] = image[i, j, 2]  # Blau behalten\n",
    "                else:\n",
    "                    # Fall für Grün (1) (zwischen Blau und Rot)\n",
    "                    d[i, j, 0] = (image[i-1, j, 0] + image[i+1, j, 0]) / 2  # Rot von oben und unten\n",
    "                    d[i, j, 1] = image[i, j, 1]  # Grün behalten\n",
    "                    d[i, j, 2] = (image[i, j-1, 2] + image[i, j+1, 2]) / 2  # Blau von links und rechts\n",
    "\n",
    "    # Rückkonvertierung auf 8-bit (Werte zwischen 0 und 255)\n",
    "    d = np.clip(np.round(d), 0, 255).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    return d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e613c63e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c22918b8d6a69fb8578911bd8ff45c6",
     "grade": true,
     "grade_id": "cell-bde846b32cd87d8c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "d_average = demosaic_average(mosaic)\n",
    "d_average_detail = d_average[250:300,300:350,:]\n",
    "\n",
    "# test values for all 4 cases\n",
    "np.testing.assert_array_equal(d_average[260, 360,:], [86, 18, 57])\n",
    "np.testing.assert_array_equal(d_average[261, 360,:], [87, 20, 61])\n",
    "np.testing.assert_array_equal(d_average[260, 361,:], [103, 28, 61])\n",
    "np.testing.assert_array_equal(d_average[261, 361,:], [102, 26, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fd4384",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(d_average_detail) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d63a0",
   "metadata": {},
   "source": [
    "As we can see, the result is quite nice and smooth. Now the only problem is that it is almost too smooth, as in some places 4 pixel values were averaged. If there would be an edge at such a position, it would get blurred and the image will appear less sharp.\n",
    "\n",
    "### Optional: Experiment with gradient techniques\n",
    "\n",
    "So a more advanced solution that is also similar to what is done in the camera, is to determine if there is a local gradient at an image position and then use an appropriate averaging technique. If there is no gradient, we use the averaging above. If there is a strong gradient in horizontal direction (so there is a vertical edge), then we only average in the vertical direction etc.\n",
    "\n",
    "This exercise is optional. Feel free to experiment with the idea of using gradients and see if you can obtain nicer results. Or you might want to come back to this after we have discussed gradients and edge detection a bit more in the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b581ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demosaic_gradient(image_8bit:np.ndarray)->np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement demosaicing of the input image \n",
    "    \"\"\"\n",
    "    # generate the target image of the same size as the original\n",
    "    d = np.zeros_like(image_8bit)\n",
    "    \n",
    "    # convert image to int before processing\n",
    "    image = image_8bit.astype(int)\n",
    "    \n",
    "    # ...\n",
    "    \n",
    "    return d\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff09bbb",
   "metadata": {},
   "source": [
    "## Exercise 2: Exposure and noise reduction\n",
    "\n",
    "We will look at some simple image manipulation, again using the skimage library.\n",
    "\n",
    "The image below has been taken in low light with a ISO setting of 10000 and with too short exposure, so it is too dark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf74c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_1 = skimage.io.imread(path + 'DSC_7757.tif')\n",
    "plt.imshow(duck_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1681c7c9",
   "metadata": {},
   "source": [
    "The first task is too make it brighter. In the exposure module of the skimage library\n",
    "\n",
    "https://scikit-image.org/docs/dev/api/skimage.exposure.html\n",
    "\n",
    "there are some functions that could help, or it could be done directly in numpy. Change the image so that the brightest value as full brightness and store the result in a variable duck_bright."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c1b5a3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a10b8b04c97905135d4d3677c79a9f4d",
     "grade": false,
     "grade_id": "cell-cb66273abae9200f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# calculate a brighter version of the image and store it in a variable duck_bright\n",
    "# you might want to try different approaches\n",
    "\n",
    "duck_bright = skimage.exposure.adjust_log(duck_1, gain=20)\n",
    "plt.imshow(duck_bright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baa7f11",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b612ba8ad4efeb6ae86f884e736c0f8",
     "grade": true,
     "grade_id": "cell-e1cf9076e4d1e5f5",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# we should use the whole color range normally for an image, except if there are some \n",
    "# special effects to achieve, so we want the maximum value to be 255 and the average to be brighter\n",
    "\n",
    "assert np.max(duck_bright) == 255\n",
    "assert np.average(duck_bright) > np.average(duck_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987d10a6",
   "metadata": {},
   "source": [
    "If you found a function to make the image brigher, it should probably be ok now. However, as the ISO value was very high, the image is very noisy. We would like to picture the noise. There are some advanced methods to estimate noise from a single image (see https://people.csail.mit.edu/billf/publications/Noise_Estimation_Single_Image.pdf), but the simplest method is to find a region with approximate constant color and plot the value distribution. Lets do that for the top right region in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc4725",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = duck_1[0:250,-250:,:]\n",
    "plt.imshow(roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f8eb8c",
   "metadata": {},
   "source": [
    "We can also display it as a line graph for all the pictures, and of course we could calculate the std deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3e264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_1d = roi.reshape(-1)\n",
    "print(np.std(roi_1d))\n",
    "plt.plot(roi_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c0e0ce",
   "metadata": {},
   "source": [
    "### Noise reduction\n",
    "\n",
    "If the noise is caused by the sensor, then it would change with each picture that we take, even if the other settings are the same. So if we have multiple images, we can combine them to create a better image with less noise.\n",
    "\n",
    "Implement a function that takes a list of images and combines them. In the cell below, your function will be called with a total of 10 images similarly to the one above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efdf581",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b99699f0e0891b42f61716660fb21683",
     "grade": false,
     "grade_id": "cell-0ae7d8c053a97adc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def combine_images(image_list)-> np.ndarray:\n",
    "    \"\"\"\n",
    "    Combine the images in the list to produce a better image.\n",
    "    \"\"\"\n",
    "    final_image = np.zeros_like(image_list[0], dtype=np.float32)\n",
    "    \n",
    "    # convert image to int before processing\n",
    "    image_32bit = image_list[0].astype(np.int32)\n",
    "    for img in image_list:\n",
    "        final_image += img.astype(np.float32)\n",
    "    final_image = final_image / len(image_list)\n",
    "    return np.clip(final_image, 0, 255).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0019093",
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_names = [path + 'DSC_7757.tif',\n",
    "              path + 'DSC_7758.tif',\n",
    "              path + 'DSC_7759.tif',\n",
    "              path + 'DSC_7760.tif',\n",
    "              path + 'DSC_7761.tif',\n",
    "              path + 'DSC_7762.tif',\n",
    "              path + 'DSC_7763.tif',\n",
    "              path + 'DSC_7764.tif',\n",
    "              path + 'DSC_7765.tif',\n",
    "              path + 'DSC_7766.tif']\n",
    "duck_images = skimage.io.imread_collection(duck_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffb3daf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4209fcea912a40ad2d2a256699577a2",
     "grade": true,
     "grade_id": "cell-3fade874d1b9a333",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "duck_combined = combine_images(duck_images)\n",
    "plt.imshow(duck_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728dd93d",
   "metadata": {},
   "source": [
    "The picture will still be a bit noisy, as there were only 10 images, but should be better than any of the single images. In order to get a nicer picture, you would have to take even more images.\n",
    "\n",
    "We will quickly look at the noise distribution as before and see if the std has gone down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e876b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_combined = duck_combined[0:250,-250:,:]\n",
    "plt.imshow(roi_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9193cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.std(roi_combined))\n",
    "plt.plot(np.reshape(roi_combined, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079ac307",
   "metadata": {},
   "source": [
    "\n",
    "Finally, we can make the combined image also a bit brighter again and display it. That will be all for the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96832f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(skimage.exposure.adjust_gamma(duck_combined, 0.5, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8896ec-2749-4c53-8e01-93cd6e825873",
   "metadata": {},
   "source": [
    "That is all for this part, the exercise continues in the other notebook. Before handing in the notebook, please clear all outputs to make the file smaller."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
